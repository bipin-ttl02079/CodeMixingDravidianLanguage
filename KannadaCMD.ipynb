{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KannadaCMD.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mithunkumarsr/CodeMixingDravidianLanguage/blob/main/KannadaCMD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEyEcB2A4dmA"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "\n",
        "from sklearn.metrics import accuracy_score,classification_report, f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uS6kc4z_8qa"
      },
      "source": [
        "nlp = spacy.load('en', disable=['parser', 'ner'])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGgxWSNw42U2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05cb4a1e-5208-42c7-a72f-2e4002d92da1"
      },
      "source": [
        "# DATA CLEANING AND PREPARATION #\n",
        "class Utils(object):\n",
        "\n",
        "    def cleanText(self, text):\n",
        "        review = re.sub(r\"^https://t.co/[a-zA-Z0-9]*\\s\", \" \", str(text))\n",
        "        review = re.sub(r\"\\([\\s\\S]*\\)\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+https://t.co/[a-zA-Z0-9]*\\s\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+https://t.co/[a-zA-Z0-9]*$\", \" \", str(review))\n",
        "        review = review.lower()\n",
        "        review = re.sub(r\"that's\", \"that is\", str(review))\n",
        "        review = re.sub(r\"there's\", \"there is\", str(review))\n",
        "        review = re.sub(r\"what's\", \"what is\", str(review))\n",
        "        review = re.sub(r\"where's\", \"where is\", str(review))\n",
        "        review = re.sub(r\"it's\", \"it is\", str(review))\n",
        "        review = re.sub(r\"who's\", \"who is\", str(review))\n",
        "        review = re.sub(r\"i'm\", \"i am\", str(review))\n",
        "        review = re.sub(r\"she's\", \"she is\", str(review))\n",
        "        review = re.sub(r\"he's\", \"he is\", str(review))\n",
        "        review = re.sub(r\"they're\", \"they are\", str(review))\n",
        "        review = re.sub(r\"who're\", \"who are\", str(review))\n",
        "        review = re.sub(r\"ain't\", \"am not\", str(review))\n",
        "        review = re.sub(r\"wouldn't\", \"would not\", str(review))\n",
        "        review = re.sub(r\"shouldn't\", \"should not\", str(review))\n",
        "        review = re.sub(r\"can't\", \"can not\", str(review))\n",
        "        review = re.sub(r\"couldn't\", \"could not\", str(review))\n",
        "        review = re.sub(r\"won't\", \"will not\", str(review))\n",
        "        review = re.sub(r\" pm \", \" \", str(review))\n",
        "        review = re.sub(r\" am \", \" \", str(review))\n",
        "        review = re.sub(r'[^\\[\\]]+(?=\\])', \" \", str(review))\n",
        "        review = re.sub(r\"\\W\", \" \", str(review))\n",
        "        review = re.sub(r\"\\d\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+[a-z]\\s+\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+[a-z]$\", \" \", str(review))\n",
        "        review = re.sub(r\"^[a-z]\\s+\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+\", \" \", str(review))\n",
        "        return review\n",
        "\n",
        "    def remove_punc(self, text):\n",
        "        table = str.maketrans(\"\", \"\", string.punctuation)\n",
        "        return text.translate(table)\n",
        "\n",
        "    def remove_emoticon(self, text):\n",
        "        emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "        return emoji_pattern.sub(r'', text)\n",
        "\n",
        "\n",
        "    \n",
        "    def lemmatization(self, text):\n",
        "        doc = nlp(text)\n",
        "        return \" \".join([token.lemma_ for token in doc])\n",
        "\n",
        "    nltk.download('stopwords')\n",
        "    def remove_stops(self, text):\n",
        "        stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "        text = [word.lower() for word in text.split() if word.lower() not in stop_words]\n",
        "        return \" \".join(text)\n",
        "\n",
        "\n",
        "    def readData1(self, path, inputColumnIndex=0, outputColumnIndex=1):\n",
        "        df = pd.read_csv(path, error_bad_lines=False, sep='\\t')\n",
        "        X = df.iloc[:, inputColumnIndex].values\n",
        "        y = df.iloc[:, outputColumnIndex].values\n",
        "        return X,y\n",
        "    \n",
        "    def readData2(self, path, inputColumnIndex=1, outputColumnIndex=2):\n",
        "        df = pd.read_csv(path, error_bad_lines=False, sep='\\t')\n",
        "        X = df.iloc[:, inputColumnIndex].values\n",
        "        y = df.iloc[:, outputColumnIndex].values\n",
        "        return X,y\n",
        "    \n",
        "    def draw_prediction_results(self, y_pred, y_test, my_tags, method):\n",
        "        print('accuracy of ' + method + ': %s' % accuracy_score(y_pred, y_test))\n",
        "        print(classification_report(y_test, y_pred, target_names=my_tags, digits = 6))\n",
        "\n",
        "    \n",
        "    def crossValidation(self, prediction, input, output, k=5):\n",
        "        scores = cross_val_score(prediction, input,output, cv=k)\n",
        "        print(\"Accuracy of Cross Validation Mean: %0.6f (+/- %0.6f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "727sZupe6Gxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf3940c-28f6-4de5-8ff2-aee55301c6dc"
      },
      "source": [
        "# FUNCTION CALL FOR DATA CLEANING AND PREPARATION #\n",
        "utils = Utils()\n",
        "X1,y_train=utils.readData1('kannada_sentiment_full_train.tsv')\n",
        "\n",
        "ourTags =['not-Kannada', 'unknown_state', 'Positive', 'Mixed_feelings', 'Negative']\n",
        "X_train=[]\n",
        "\n",
        "for i in range(0, len(X1)):\n",
        "    t = utils.cleanText(X1[i])\n",
        "    t = utils.remove_emoticon(t)\n",
        "    t = utils.remove_punc(t)\n",
        "    t = utils.remove_stops(t)\n",
        "    t = utils.lemmatization(t)\n",
        "    X_train.append(t)\n",
        "\n",
        "print(X_train[:10])\n",
        "#X_train, X_test, y_train, y_test = train_test_split(corpus, y, test_size=0.3, random_state=0)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ಒ ದ ದ ಶದ ಮ ದ ವರ ಯ ವ ದ ಅದರ ಆರ ಥ ಕ ಸ ಥ ತ ಯನ ನ ಅವಲ ಬ ಸ ವ ದ ಲ ಲ ಅವರ ಮ ನವ ಯತ ಯಲ ಲ ಎಷ ಟ ಸಮರ ಥರ ಎನ ನ ವ ದನ ನ ಅವಲ ಬ ಸ ದ ಭ ರತದಲ ಲ ಅನಕ ಷರತ ಇದ ಆ ಅನಕ ಷರಸ ಥರನ ನ ಅವರ ಅನಕ ಷರತ ಯ', 'ಕನ ನಡದಲ ಲ ಡ ಲ ಟ ಕ ಅಪ ಡ ಟ ಸ ಪಡ ಯಲ ಸಬ ಸ ಕ ರ ಬ ಮ ಡ ನಮ ಮ ಚನ ನ ಲ ಗ', 'super sar song', 'tiktoker present situation nನ ಡ ವವರ ಯ ರ ನಮ ಮ ವ ಡ ಯ ನ', 'super ಸ ಗ ವ ರ ನ ಸ', 'varshakke thagadu movie madi industry haal mado hero galu ondh kade adrenn varsha kasta pattu ondhu olle film mado namma rakshith shetty haagu yash innondh kade', 'tickets amount adru mosa illa love', 'super super super film explain', 'wild rex ಕಟ ಟಬ ಕ bronಖ ಡ ತ ಕಟ ಟ ತ ತ bro', 'shankaragouda desaigoudra super']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPsszKRGni1Z"
      },
      "source": [
        "# FUNCTION CALL FOR DATA CLEANING AND PREPARATION #\n",
        "utils = Utils()\n",
        "X2,y_test=utils.readData2('kannada_sentiment_full_test_withlabels.tsv')\n",
        "\n",
        "X_test=[]\n",
        "\n",
        "for i in range(0, len(X2)):\n",
        "    t = utils.cleanText(X2[i])\n",
        "    t = utils.remove_emoticon(t)\n",
        "    t = utils.remove_punc(t)\n",
        "    t = utils.remove_stops(t)\n",
        "    t = utils.lemmatization(t)\n",
        "    X_test.append(t)\n",
        "#print(corpus)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqPVciOg-K5c"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODSXTCHsLd8Q",
        "outputId": "da2c87d7-684f-4159-8d25-d8daee3c2458"
      },
      "source": [
        "# LOGISTIC REGRESSION #\n",
        "lrp = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2,analyzer='word', ngram_range=(1, 3))),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('lr', LogisticRegression(max_iter=1000))\n",
        "                ])\n",
        "lrp.fit(X_train, y_train)\n",
        "y_pred = lrp.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(y_pred,y_test,ourTags,\"Logistic Regression\")\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Logistic Regression: 0.6158854166666666\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   not-Kannada   0.444444  0.061538  0.108108        65\n",
            " unknown_state   0.642857  0.573248  0.606061       157\n",
            "      Positive   0.627490  0.842246  0.719178       374\n",
            "Mixed_feelings   0.597701  0.472727  0.527919       110\n",
            "      Negative   0.400000  0.193548  0.260870        62\n",
            "\n",
            "      accuracy                       0.615885       768\n",
            "     macro avg   0.542499  0.428662  0.444427       768\n",
            "  weighted avg   0.592508  0.615885  0.579943       768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGB5YURAThfx",
        "outputId": "0da6f9a2-1f3e-410d-8f77-564c658a6387"
      },
      "source": [
        "# MULTINOMIAL NAIVE BAYES #\n",
        "multinomial_naive_bayes = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('multinomial_naive_bayes',\n",
        "                         MultinomialNB())\n",
        "                        ])\n",
        "multinomial_naive_bayes.fit(X_train, y_train)\n",
        "pred_multinomial_naive_bayes = multinomial_naive_bayes.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_multinomial_naive_bayes,y_test,ourTags,\"Multinomial Naive Bayes\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Multinomial Naive Bayes: 0.6171875\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   not-Kannada   0.400000  0.030769  0.057143        65\n",
            " unknown_state   0.728070  0.528662  0.612546       157\n",
            "      Positive   0.602862  0.901070  0.722401       374\n",
            "Mixed_feelings   0.611111  0.400000  0.483516       110\n",
            "      Negative   0.444444  0.129032  0.200000        62\n",
            "\n",
            "      accuracy                       0.617188       768\n",
            "     macro avg   0.557298  0.397907  0.415121       768\n",
            "  weighted avg   0.599681  0.617188  0.567251       768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22IIDKIOwTaK",
        "outputId": "5d3c30ea-8a31-4ccd-be9e-6875328908b2"
      },
      "source": [
        "# LINEAR SVM #\n",
        "linear_svm = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('linear_svc',\n",
        "                        SVC(kernel='linear'))\n",
        "                        ])\n",
        "linear_svm.fit(X_train, y_train)\n",
        "y_pred_svc = linear_svm.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "\n",
        "utils.draw_prediction_results(y_pred_svc,y_test,ourTags,\"Linear SVM\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Linear SVM: 0.6041666666666666\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   not-Kannada   0.312500  0.076923  0.123457        65\n",
            " unknown_state   0.611111  0.560510  0.584718       157\n",
            "      Positive   0.640167  0.818182  0.718310       374\n",
            "Mixed_feelings   0.556701  0.490909  0.521739       110\n",
            "      Negative   0.333333  0.177419  0.231579        62\n",
            "\n",
            "      accuracy                       0.604167       768\n",
            "     macro avg   0.490763  0.424789  0.435960       768\n",
            "  weighted avg   0.569770  0.604167  0.573206       768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1cYONgUxcBy",
        "outputId": "fc309718-ba0b-455e-91c6-adc12aa58f25"
      },
      "source": [
        "# RBF SVM #\n",
        "rbf_svm = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('rbf_svc',\n",
        "                        SVC(kernel='rbf', gamma=1))\n",
        "                        ])\n",
        "rbf_svm.fit(X_train, y_train)\n",
        "y_pred_svc = rbf_svm.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(y_pred_svc,y_test,ourTags,\"RBF SVM\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of RBF SVM: 0.6158854166666666\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   not-Kannada   0.428571  0.046154  0.083333        65\n",
            " unknown_state   0.675439  0.490446  0.568266       157\n",
            "      Positive   0.629703  0.850267  0.723549       374\n",
            "Mixed_feelings   0.619565  0.518182  0.564356       110\n",
            "      Negative   0.360000  0.290323  0.321429        62\n",
            "\n",
            "      accuracy                       0.615885       768\n",
            "     macro avg   0.542656  0.439074  0.452187       768\n",
            "  weighted avg   0.598805  0.615885  0.582356       768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-ucCcstztRa",
        "outputId": "22f5dbdc-a3ac-4792-c197-f753f99041af"
      },
      "source": [
        "# POLY SVM #\n",
        "poly_svm = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('poly_svc',\n",
        "                        SVC(kernel='poly',degree = 1))\n",
        "                        ])\n",
        "poly_svm.fit(X_train, y_train)\n",
        "y_pred_svc = poly_svm.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(y_pred_svc,y_test,ourTags,\"POLY SVM\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of POLY SVM: 0.60546875\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   not-Kannada   0.294118  0.076923  0.121951        65\n",
            " unknown_state   0.618056  0.566879  0.591362       157\n",
            "      Positive   0.640167  0.818182  0.718310       374\n",
            "Mixed_feelings   0.556701  0.490909  0.521739       110\n",
            "      Negative   0.343750  0.177419  0.234043        62\n",
            "\n",
            "      accuracy                       0.605469       768\n",
            "     macro avg   0.490558  0.426062  0.437481       768\n",
            "  weighted avg   0.570475  0.605469  0.574636       768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5ovnOnrv6-Z",
        "outputId": "1afa2bc7-b57b-4117-f43f-3d6e6cf165e8"
      },
      "source": [
        "# RANDOM FOREST #\n",
        "random_forest = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('random_forest',\n",
        "                         RandomForestClassifier())\n",
        "                        ])\n",
        "random_forest.fit(X_train, y_train)\n",
        "pred_random_forest = random_forest.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_random_forest,y_test,ourTags,\"Random Forest\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Random Forest: 0.5625\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   not-Kannada   0.125000  0.030769  0.049383        65\n",
            " unknown_state   0.652542  0.490446  0.560000       157\n",
            "      Positive   0.645309  0.754011  0.695438       374\n",
            "Mixed_feelings   0.473684  0.490909  0.482143       110\n",
            "      Negative   0.204819  0.274194  0.234483        62\n",
            "\n",
            "      accuracy                       0.562500       768\n",
            "     macro avg   0.420271  0.408066  0.404289       768\n",
            "  weighted avg   0.542609  0.562500  0.545309       768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s31N5aEL8rIu",
        "outputId": "ad84592f-77e1-4c59-fd0f-10616777dd0b"
      },
      "source": [
        "# KNeighborsClassifier #\n",
        "knn = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('kNN', KNeighborsClassifier(n_neighbors=3))\n",
        "                        ])\n",
        "knn.fit(X_train, y_train)\n",
        "pred_knn = knn.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_knn,y_test,ourTags,\"KNeighborsClassifier\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of KNeighborsClassifier: 0.3776041666666667\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   not-Kannada   0.142857  0.138462  0.140625        65\n",
            " unknown_state   0.621212  0.261146  0.367713       157\n",
            "      Positive   0.725118  0.409091  0.523077       374\n",
            "Mixed_feelings   0.191816  0.681818  0.299401       110\n",
            "      Negative   0.324324  0.193548  0.242424        62\n",
            "\n",
            "      accuracy                       0.377604       768\n",
            "     macro avg   0.401066  0.336813  0.314648       768\n",
            "  weighted avg   0.545857  0.377604  0.404254       768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc8SBEBsMeo8"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import StackingClassifier"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm7FWo_vNqbS",
        "outputId": "89627fcf-bfab-453b-a87e-aafaf905a85c"
      },
      "source": [
        "# EXTRA TREE CLASSIFIER #\n",
        "extra_tree = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('extra tree',\n",
        "                         ExtraTreesClassifier())\n",
        "                        ])\n",
        "extra_tree.fit(X_train, y_train)\n",
        "pred_extra_tree = extra_tree.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_extra_tree,y_test,ourTags,\"Extra Tree Classifier\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Extra Tree Classifier: 0.5768229166666666\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   not-Kannada   0.173913  0.061538  0.090909        65\n",
            " unknown_state   0.671875  0.547771  0.603509       157\n",
            "      Positive   0.665060  0.737968  0.699620       374\n",
            "Mixed_feelings   0.495798  0.536364  0.515284       110\n",
            "      Negative   0.216867  0.290323  0.248276        62\n",
            "\n",
            "      accuracy                       0.576823       768\n",
            "     macro avg   0.444703  0.434793  0.431519       768\n",
            "  weighted avg   0.564459  0.576823  0.565615       768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCP0liD9P5Mq",
        "outputId": "1aa5b044-5570-4ae0-f6a4-069fc4d88b3c"
      },
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# ALL CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp), (\"Multinomial Naive Bayes\", multinomial_naive_bayes), (\"Extra Tree\", extra_tree), (\"Random Forest\", random_forest), (\"Poly SVM\", poly_svm), (\"RBF SVM\", rbf_svm), (\"KNeighborsClassifier\", knn)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Hard Ensemble: 0.6158854166666666\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   not-Kannada   0.400000  0.061538  0.106667        65\n",
            " unknown_state   0.659091  0.554140  0.602076       157\n",
            "      Positive   0.625247  0.847594  0.719637       374\n",
            "Mixed_feelings   0.574468  0.490909  0.529412       110\n",
            "      Negative   0.440000  0.177419  0.252874        62\n",
            "\n",
            "      accuracy                       0.615885       768\n",
            "     macro avg   0.539761  0.426320  0.442133       768\n",
            "  weighted avg   0.590874  0.615885  0.578798       768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtugxjUBOlbA",
        "outputId": "f5ba00ad-6f63-47b8-fffd-ff2d61f31b0d"
      },
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# TOP 5 CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp),  (\"Random Forest\", random_forest), (\"Poly SVM\", poly_svm), (\"RBF SVM\", rbf_svm)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Hard Ensemble: 0.6106770833333334\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   not-Kannada   0.416667  0.076923  0.129870        65\n",
            " unknown_state   0.625899  0.554140  0.587838       157\n",
            "      Positive   0.631048  0.836898  0.719540       374\n",
            "Mixed_feelings   0.569892  0.481818  0.522167       110\n",
            "      Negative   0.392857  0.177419  0.244444        62\n",
            "\n",
            "      accuracy                       0.610677       768\n",
            "     macro avg   0.527273  0.425440  0.440772       768\n",
            "  weighted avg   0.583863  0.610677  0.576086       768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2WVBt7tQ0MA",
        "outputId": "4178e313-16e5-46ae-da06-3ffbfd067578"
      },
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# TOP 3 CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp), (\"Poly SVM\", poly_svm)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Hard Ensemble: 0.60546875\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   not-Kannada   0.294118  0.076923  0.121951        65\n",
            " unknown_state   0.613793  0.566879  0.589404       157\n",
            "      Positive   0.641509  0.818182  0.719154       374\n",
            "Mixed_feelings   0.556701  0.490909  0.521739       110\n",
            "      Negative   0.343750  0.177419  0.234043        62\n",
            "\n",
            "      accuracy                       0.605469       768\n",
            "     macro avg   0.489974  0.426062  0.437258       768\n",
            "  weighted avg   0.570257  0.605469  0.574647       768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tevtGnJ6RIYh",
        "outputId": "5f128289-f811-455e-c85b-17073f976bee"
      },
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# BEST OF ALL CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp), (\"Multinomial Naive Bayes\", multinomial_naive_bayes), (\"Extra Tree\", extra_tree)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Hard Ensemble: 0.6236979166666666\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   not-Kannada   0.454545  0.076923  0.131579        65\n",
            " unknown_state   0.650350  0.592357  0.620000       157\n",
            "      Positive   0.630435  0.852941  0.725000       374\n",
            "Mixed_feelings   0.611765  0.472727  0.533333       110\n",
            "      Negative   0.434783  0.161290  0.235294        62\n",
            "\n",
            "      accuracy                       0.623698       768\n",
            "     macro avg   0.556375  0.431248  0.449041       768\n",
            "  weighted avg   0.601151  0.623698  0.586325       768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrvYzJMSSl2H",
        "outputId": "a6e7eefe-df07-42d1-cd71-6ec694cea349"
      },
      "source": [
        "# ADABOOST #\n",
        "#seed = 10\n",
        "num_trees = 25\n",
        "\n",
        "ada_boost = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('ada_boost',\n",
        "                         AdaBoostClassifier(n_estimators=num_trees))\n",
        "                        ])\n",
        "ada_boost.fit(X_train, y_train)\n",
        "pred_ada_boost = ada_boost.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_ada_boost,y_test,ourTags,\"Ada Boost\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Ada Boost: 0.5403645833333334\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   not-Kannada   0.600000  0.046154  0.085714        65\n",
            " unknown_state   0.706897  0.261146  0.381395       157\n",
            "      Positive   0.537500  0.919786  0.678501       374\n",
            "Mixed_feelings   0.511628  0.200000  0.287582       110\n",
            "      Negative   0.227273  0.080645  0.119048        62\n",
            "\n",
            "      accuracy                       0.540365       768\n",
            "     macro avg   0.516659  0.301546  0.310448       768\n",
            "  weighted avg   0.548669  0.540365  0.466439       768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVaP26seRJN8",
        "outputId": "0d8dbe9c-e60d-438d-9606-88ff95d9df35"
      },
      "source": [
        "# XGBOOST #\n",
        "xg_boost = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('xgboost',\n",
        "                         XGBClassifier())\n",
        "                        ])\n",
        "xg_boost.fit(X_train, y_train)\n",
        "pred_xg_boost = xg_boost.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_xg_boost,y_test,ourTags,\"XGBoost\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of XGBoost: 0.5520833333333334\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   not-Kannada   0.400000  0.030769  0.057143        65\n",
            " unknown_state   0.701493  0.299363  0.419643       157\n",
            "      Positive   0.535769  0.941176  0.682832       374\n",
            "Mixed_feelings   0.594595  0.200000  0.299320       110\n",
            "      Negative   0.500000  0.016129  0.031250        62\n",
            "\n",
            "      accuracy                       0.552083       768\n",
            "     macro avg   0.546371  0.297488  0.298038       768\n",
            "  weighted avg   0.563694  0.552083  0.468542       768\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai2QQGdioGlJ",
        "outputId": "93c8a3be-1169-496e-ff55-e9b18e27e193"
      },
      "source": [
        "# XGBOOST #\n",
        "xg_boost = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('xgboost',\n",
        "                         XGBClassifier(learning_rate =0.1,\n",
        " n_estimators=1000,\n",
        " max_depth=5,\n",
        " min_child_weight=1,\n",
        " gamma=0,\n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " nthread=4,\n",
        " scale_pos_weight=1,\n",
        " seed=27))\n",
        "])\n",
        "xg_boost.fit(X_train, y_train)\n",
        "pred_xg_boost = xg_boost.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_xg_boost,y_test,ourTags,\"XGBoost\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of XGBoost: 0.5690104166666666\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "   not-Kannada   0.259259  0.107692  0.152174        65\n",
            " unknown_state   0.622222  0.535032  0.575342       157\n",
            "      Positive   0.628009  0.767380  0.690734       374\n",
            "Mixed_feelings   0.495413  0.490909  0.493151       110\n",
            "      Negative   0.125000  0.080645  0.098039        62\n",
            "\n",
            "      accuracy                       0.569010       768\n",
            "     macro avg   0.425981  0.396332  0.401888       768\n",
            "  weighted avg   0.536017  0.569010  0.545416       768\n",
            "\n"
          ]
        }
      ]
    }
  ]
}