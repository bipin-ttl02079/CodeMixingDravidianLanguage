{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MalayalamCMD.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mithunkumarsr/CodeMixingDravidianLanguage/blob/main/MalayalamCMD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEyEcB2A4dmA"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "\n",
        "from sklearn.metrics import accuracy_score,classification_report, f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uS6kc4z_8qa"
      },
      "source": [
        "nlp = spacy.load('en', disable=['parser', 'ner'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGgxWSNw42U2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3764127-3e1e-4651-b53b-51307e8b8f3d"
      },
      "source": [
        "# DATA CLEANING AND PREPARATION #\n",
        "class Utils(object):\n",
        "\n",
        "    def cleanText(self, text):\n",
        "        review = re.sub(r\"^https://t.co/[a-zA-Z0-9]*\\s\", \" \", str(text))\n",
        "        review = re.sub(r\"\\([\\s\\S]*\\)\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+https://t.co/[a-zA-Z0-9]*\\s\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+https://t.co/[a-zA-Z0-9]*$\", \" \", str(review))\n",
        "        review = review.lower()\n",
        "        review = re.sub(r\"that's\", \"that is\", str(review))\n",
        "        review = re.sub(r\"there's\", \"there is\", str(review))\n",
        "        review = re.sub(r\"what's\", \"what is\", str(review))\n",
        "        review = re.sub(r\"where's\", \"where is\", str(review))\n",
        "        review = re.sub(r\"it's\", \"it is\", str(review))\n",
        "        review = re.sub(r\"who's\", \"who is\", str(review))\n",
        "        review = re.sub(r\"i'm\", \"i am\", str(review))\n",
        "        review = re.sub(r\"she's\", \"she is\", str(review))\n",
        "        review = re.sub(r\"he's\", \"he is\", str(review))\n",
        "        review = re.sub(r\"they're\", \"they are\", str(review))\n",
        "        review = re.sub(r\"who're\", \"who are\", str(review))\n",
        "        review = re.sub(r\"ain't\", \"am not\", str(review))\n",
        "        review = re.sub(r\"wouldn't\", \"would not\", str(review))\n",
        "        review = re.sub(r\"shouldn't\", \"should not\", str(review))\n",
        "        review = re.sub(r\"can't\", \"can not\", str(review))\n",
        "        review = re.sub(r\"couldn't\", \"could not\", str(review))\n",
        "        review = re.sub(r\"won't\", \"will not\", str(review))\n",
        "        review = re.sub(r\" pm \", \" \", str(review))\n",
        "        review = re.sub(r\" am \", \" \", str(review))\n",
        "        review = re.sub(r'[^\\[\\]]+(?=\\])', \" \", str(review))\n",
        "        review = re.sub(r\"\\W\", \" \", str(review))\n",
        "        review = re.sub(r\"\\d\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+[a-z]\\s+\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+[a-z]$\", \" \", str(review))\n",
        "        review = re.sub(r\"^[a-z]\\s+\", \" \", str(review))\n",
        "        review = re.sub(r\"\\s+\", \" \", str(review))\n",
        "        return review\n",
        "\n",
        "    def remove_punc(self, text):\n",
        "        table = str.maketrans(\"\", \"\", string.punctuation)\n",
        "        return text.translate(table)\n",
        "\n",
        "    def remove_emoticon(self, text):\n",
        "        emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "        return emoji_pattern.sub(r'', text)\n",
        "\n",
        "\n",
        "    \n",
        "    def lemmatization(self, text):\n",
        "        doc = nlp(text)\n",
        "        return \" \".join([token.lemma_ for token in doc])\n",
        "\n",
        "    nltk.download('stopwords')\n",
        "    def remove_stops(self, text):\n",
        "        stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "        text = [word.lower() for word in text.split() if word.lower() not in stop_words]\n",
        "        return \" \".join(text)\n",
        "\n",
        "\n",
        "    def readData1(self, path, inputColumnIndex=0, outputColumnIndex=1):\n",
        "        df = pd.read_csv(path, error_bad_lines=False, sep='\\t')\n",
        "        X = df.iloc[:, inputColumnIndex].values\n",
        "        y = df.iloc[:, outputColumnIndex].values\n",
        "        return X,y\n",
        "    \n",
        "    def readData2(self, path, inputColumnIndex=1, outputColumnIndex=2):\n",
        "        df = pd.read_csv(path, error_bad_lines=False, sep='\\t')\n",
        "        X = df.iloc[:, inputColumnIndex].values\n",
        "        y = df.iloc[:, outputColumnIndex].values\n",
        "        return X,y\n",
        "    \n",
        "    def draw_prediction_results(self, y_pred, y_test, my_tags, method):\n",
        "        print('accuracy of ' + method + ': %s' % accuracy_score(y_pred, y_test))\n",
        "        print(classification_report(y_test, y_pred, target_names=my_tags, digits = 6))\n",
        "\n",
        "    \n",
        "    def crossValidation(self, prediction, input, output, k=5):\n",
        "        scores = cross_val_score(prediction, input,output, cv=k)\n",
        "        print(\"Accuracy of Cross Validation Mean: %0.6f (+/- %0.6f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "727sZupe6Gxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2037a232-f6cd-43c8-b0a1-0839966604ce"
      },
      "source": [
        "# FUNCTION CALL FOR DATA CLEANING AND PREPARATION #\n",
        "utils = Utils()\n",
        "X1,y_train=utils.readData1('Mal_sentiment_full_train.tsv')\n",
        "\n",
        "ourTags =['not-Tamil', 'unknown_state', 'Positive', 'Mixed_feelings', 'Negative']\n",
        "X_train=[]\n",
        "\n",
        "for i in range(0, len(X1)):\n",
        "    t = utils.cleanText(X1[i])\n",
        "    t = utils.remove_emoticon(t)\n",
        "    t = utils.remove_punc(t)\n",
        "    t = utils.remove_stops(t)\n",
        "    t = utils.lemmatization(t)\n",
        "    X_train.append(t)\n",
        "\n",
        "print(X_train[:10])\n",
        "#X_train, X_test, y_train, y_test = train_test_split(corpus, y, test_size=0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sunny chechi fan evide like adichu power kaniku', 'angane july month ile ende aadyathe leave njan angu edukuva july nu', 'ഏട ടന റ പ ത യ പടത ത ന വ ണ ട ക ത ത ര ക ക ന നവർ ല ക ബട ടൺ അട ച ച പ ള ക ക', 'ഇന ല ല ട ടന റ വ ട ട ത ടങ ങ ൻ പ ക ന ന മ ൻ ക ല collection recordukal ഭ ത ച ച ര ക ക', 'trailer powli oru raksha illa pakshea padam irangattea veruthea degrade venda padam irangittu paraya', 'malayalam padam thanne aanu vere level', 'history mammukka kattawaiting support love mammukka', 'yaaru andha mech le penne', 'ആമയ വ ള ളത ത ൽ മ ക ക ക ല ല ന ന ഇനമ', 'ജ ഷ രണ ട കല പ ച ച ആണ ല ല സ ഭവ എന ത യ ല പ ള ക ക']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPsszKRGni1Z"
      },
      "source": [
        "# FUNCTION CALL FOR DATA CLEANING AND PREPARATION #\n",
        "utils = Utils()\n",
        "X2,y_test=utils.readData2('Mal_sentiment_full_test_withlabels.tsv')\n",
        "\n",
        "X_test=[]\n",
        "\n",
        "for i in range(0, len(X2)):\n",
        "    t = utils.cleanText(X2[i])\n",
        "    t = utils.remove_emoticon(t)\n",
        "    t = utils.remove_punc(t)\n",
        "    t = utils.remove_stops(t)\n",
        "    t = utils.lemmatization(t)\n",
        "    X_test.append(t)\n",
        "#print(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqPVciOg-K5c"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODSXTCHsLd8Q",
        "outputId": "1e5a7abe-32f7-4b23-db87-53526d58849f"
      },
      "source": [
        "# LOGISTIC REGRESSION #\n",
        "lrp = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2,analyzer='word', ngram_range=(1, 3))),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('lr', LogisticRegression(max_iter=1000))\n",
        "                ])\n",
        "lrp.fit(X_train, y_train)\n",
        "y_pred = lrp.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(y_pred,y_test,ourTags,\"Logistic Regression\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Logistic Regression: 0.6605504587155964\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.647059  0.164179  0.261905       134\n",
            " unknown_state   0.655844  0.391473  0.490291       258\n",
            "      Positive   0.656566  0.833333  0.734463       780\n",
            "Mixed_feelings   0.717172  0.482993  0.577236       147\n",
            "      Negative   0.659854  0.702955  0.680723       643\n",
            "\n",
            "      accuracy                       0.660550      1962\n",
            "     macro avg   0.667299  0.514987  0.548924      1962\n",
            "  weighted avg   0.661440  0.660550  0.640688      1962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGB5YURAThfx",
        "outputId": "4bd0a473-3474-4dde-b898-5c76b75a7500"
      },
      "source": [
        "# MULTINOMIAL NAIVE BAYES #\n",
        "multinomial_naive_bayes = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('multinomial_naive_bayes',\n",
        "                         MultinomialNB())\n",
        "                        ])\n",
        "multinomial_naive_bayes.fit(X_train, y_train)\n",
        "pred_multinomial_naive_bayes = multinomial_naive_bayes.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_multinomial_naive_bayes,y_test,ourTags,\"Multinomial Naive Bayes\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Multinomial Naive Bayes: 0.5958205912334352\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.666667  0.014925  0.029197       134\n",
            " unknown_state   0.731343  0.189922  0.301538       258\n",
            "      Positive   0.559738  0.876923  0.683317       780\n",
            "Mixed_feelings   0.862745  0.299320  0.444444       147\n",
            "      Negative   0.630048  0.606532  0.618067       643\n",
            "\n",
            "      accuracy                       0.595821      1962\n",
            "     macro avg   0.690108  0.397525  0.415313      1962\n",
            "  weighted avg   0.635352  0.595821  0.549157      1962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22IIDKIOwTaK",
        "outputId": "7166dcdd-876a-4c00-fdbc-80e387bca3f4"
      },
      "source": [
        "# LINEAR SVM #\n",
        "linear_svm = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('linear_svc',\n",
        "                        SVC(kernel='linear'))\n",
        "                        ])\n",
        "linear_svm.fit(X_train, y_train)\n",
        "y_pred_svc = linear_svm.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "\n",
        "utils.draw_prediction_results(y_pred_svc,y_test,ourTags,\"Linear SVM\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Linear SVM: 0.6610601427115188\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.620000  0.231343  0.336957       134\n",
            " unknown_state   0.626437  0.422481  0.504630       258\n",
            "      Positive   0.666310  0.798718  0.726531       780\n",
            "Mixed_feelings   0.673913  0.632653  0.652632       147\n",
            "      Negative   0.663158  0.685848  0.674312       643\n",
            "\n",
            "      accuracy                       0.661060      1962\n",
            "     macro avg   0.649964  0.554209  0.579012      1962\n",
            "  weighted avg   0.657441  0.661060  0.648094      1962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1cYONgUxcBy",
        "outputId": "3e7c21e0-69ea-4736-91f3-09394514c978"
      },
      "source": [
        "# RBF SVM #\n",
        "rbf_svm = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('rbf_svc',\n",
        "                        SVC(kernel='rbf', gamma=1))\n",
        "                        ])\n",
        "rbf_svm.fit(X_train, y_train)\n",
        "y_pred_svc = rbf_svm.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(y_pred_svc,y_test,ourTags,\"RBF SVM\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of RBF SVM: 0.6580020387359837\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.806452  0.186567  0.303030       134\n",
            " unknown_state   0.703125  0.348837  0.466321       258\n",
            "      Positive   0.637795  0.830769  0.721604       780\n",
            "Mixed_feelings   0.754717  0.544218  0.632411       147\n",
            "      Negative   0.657856  0.696734  0.676737       643\n",
            "\n",
            "      accuracy                       0.658002      1962\n",
            "     macro avg   0.711989  0.521425  0.560021      1962\n",
            "  weighted avg   0.673240  0.658002  0.638060      1962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-ucCcstztRa",
        "outputId": "46f8dae8-ab52-45dc-f638-8be4d9d2abbf"
      },
      "source": [
        "# POLY SVM #\n",
        "poly_svm = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('poly_svc',\n",
        "                        SVC(kernel='poly',degree = 1))\n",
        "                        ])\n",
        "poly_svm.fit(X_train, y_train)\n",
        "y_pred_svc = poly_svm.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(y_pred_svc,y_test,ourTags,\"POLY SVM\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of POLY SVM: 0.6620795107033639\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.620000  0.231343  0.336957       134\n",
            " unknown_state   0.630058  0.422481  0.505800       258\n",
            "      Positive   0.667024  0.798718  0.726954       780\n",
            "Mixed_feelings   0.673913  0.632653  0.652632       147\n",
            "      Negative   0.664168  0.688958  0.676336       643\n",
            "\n",
            "      accuracy                       0.662080      1962\n",
            "     macro avg   0.651032  0.554831  0.579736      1962\n",
            "  weighted avg   0.658531  0.662080  0.649080      1962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5ovnOnrv6-Z",
        "outputId": "d08aa9fe-4553-404c-a8ea-8b3820b92564"
      },
      "source": [
        "# RANDOM FOREST #\n",
        "random_forest = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('random_forest',\n",
        "                         RandomForestClassifier())\n",
        "                        ])\n",
        "random_forest.fit(X_train, y_train)\n",
        "pred_random_forest = random_forest.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_random_forest,y_test,ourTags,\"Random Forest\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Random Forest: 0.6350662589194699\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.605263  0.171642  0.267442       134\n",
            " unknown_state   0.633929  0.275194  0.383784       258\n",
            "      Positive   0.637487  0.793590  0.707025       780\n",
            "Mixed_feelings   0.603896  0.632653  0.617940       147\n",
            "      Negative   0.640466  0.684292  0.661654       643\n",
            "\n",
            "      accuracy                       0.635066      1962\n",
            "     macro avg   0.624208  0.511474  0.527569      1962\n",
            "  weighted avg   0.633278  0.635066  0.612953      1962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s31N5aEL8rIu",
        "outputId": "b210cf88-050c-4adb-df65-b3870a67c353"
      },
      "source": [
        "# KNeighborsClassifier #\n",
        "knn = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('kNN', KNeighborsClassifier(n_neighbors=3))\n",
        "                        ])\n",
        "knn.fit(X_train, y_train)\n",
        "pred_knn = knn.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_knn,y_test,ourTags,\"KNeighborsClassifier\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of KNeighborsClassifier: 0.45871559633027525\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.460317  0.216418  0.294416       134\n",
            " unknown_state   0.417476  0.166667  0.238227       258\n",
            "      Positive   0.634328  0.326923  0.431472       780\n",
            "Mixed_feelings   0.597701  0.353741  0.444444       147\n",
            "      Negative   0.398623  0.810264  0.534359       643\n",
            "\n",
            "      accuracy                       0.458716      1962\n",
            "     macro avg   0.501689  0.374803  0.388584      1962\n",
            "  weighted avg   0.513937  0.458716  0.431391      1962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc8SBEBsMeo8"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import StackingClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm7FWo_vNqbS",
        "outputId": "ee7edd8d-e11f-49a9-debb-015c50aaaa8d"
      },
      "source": [
        "# EXTRA TREE CLASSIFIER #\n",
        "extra_tree = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('extra tree',\n",
        "                         ExtraTreesClassifier())\n",
        "                        ])\n",
        "extra_tree.fit(X_train, y_train)\n",
        "pred_extra_tree = extra_tree.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_extra_tree,y_test,ourTags,\"Extra Tree Classifier\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Extra Tree Classifier: 0.6467889908256881\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.615385  0.238806  0.344086       134\n",
            " unknown_state   0.645669  0.317829  0.425974       258\n",
            "      Positive   0.655172  0.803846  0.721934       780\n",
            "Mixed_feelings   0.580645  0.612245  0.596026       147\n",
            "      Negative   0.652757  0.681182  0.666667       643\n",
            "\n",
            "      accuracy                       0.646789      1962\n",
            "     macro avg   0.629926  0.530782  0.550938      1962\n",
            "  weighted avg   0.644830  0.646789  0.629664      1962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCP0liD9P5Mq",
        "outputId": "38004b78-d272-4fe7-f22e-513812a7a86d"
      },
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# ALL CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp), (\"Multinomial Naive Bayes\", multinomial_naive_bayes), (\"Extra Tree\", extra_tree), (\"Random Forest\", random_forest), (\"Poly SVM\", poly_svm), (\"RBF SVM\", rbf_svm), (\"KNeighborsClassifier\", knn)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Hard Ensemble: 0.6671763506625892\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.725000  0.216418  0.333333       134\n",
            " unknown_state   0.675862  0.379845  0.486352       258\n",
            "      Positive   0.652610  0.833333  0.731982       780\n",
            "Mixed_feelings   0.735537  0.605442  0.664179       147\n",
            "      Negative   0.671212  0.688958  0.679969       643\n",
            "\n",
            "      accuracy                       0.667176      1962\n",
            "     macro avg   0.692044  0.544799  0.579163      1962\n",
            "  weighted avg   0.672921  0.667176  0.650329      1962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtugxjUBOlbA",
        "outputId": "e19e2c8e-c52c-4b4a-f16a-7e29a11145a0"
      },
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# TOP 5 CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp),  (\"Random Forest\", random_forest), (\"Poly SVM\", poly_svm), (\"RBF SVM\", rbf_svm)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Hard Ensemble: 0.6620795107033639\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.630435  0.216418  0.322222       134\n",
            " unknown_state   0.635220  0.391473  0.484412       258\n",
            "      Positive   0.660788  0.816667  0.730505       780\n",
            "Mixed_feelings   0.697674  0.612245  0.652174       147\n",
            "      Negative   0.665663  0.687403  0.676358       643\n",
            "\n",
            "      accuracy                       0.662080      1962\n",
            "     macro avg   0.657956  0.544841  0.573134      1962\n",
            "  weighted avg   0.659714  0.662080  0.646645      1962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2WVBt7tQ0MA",
        "outputId": "3166c10c-42df-4ff8-cf33-0f9996007e4f"
      },
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# TOP 3 CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp), (\"Poly SVM\", poly_svm)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Hard Ensemble: 0.6610601427115188\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.620000  0.231343  0.336957       134\n",
            " unknown_state   0.626437  0.422481  0.504630       258\n",
            "      Positive   0.666310  0.798718  0.726531       780\n",
            "Mixed_feelings   0.673913  0.632653  0.652632       147\n",
            "      Negative   0.663158  0.685848  0.674312       643\n",
            "\n",
            "      accuracy                       0.661060      1962\n",
            "     macro avg   0.649964  0.554209  0.579012      1962\n",
            "  weighted avg   0.657441  0.661060  0.648094      1962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tevtGnJ6RIYh",
        "outputId": "28b20922-4b00-43c3-8027-61a77023168f"
      },
      "source": [
        "# VOTING CLASSIFIER #\n",
        "# BEST OF ALL CLASSIFIERS #\n",
        "\n",
        "#create a dictionary of our models\n",
        "estimators=[(\"Linear SVM\", linear_svm), (\"Logistic Regression\", lrp), (\"Multinomial Naive Bayes\", multinomial_naive_bayes), (\"Extra Tree\", extra_tree)]\n",
        "\n",
        "hard_ensemble = VotingClassifier(estimators, voting=\"hard\")\n",
        "hard_ensemble.fit(X_train, y_train)\n",
        "pred_hard_ensemble = hard_ensemble.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_hard_ensemble,y_test,ourTags,\"Hard Ensemble\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Hard Ensemble: 0.6600407747196738\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.648649  0.179104  0.280702       134\n",
            " unknown_state   0.660256  0.399225  0.497585       258\n",
            "      Positive   0.640232  0.848718  0.729879       780\n",
            "Mixed_feelings   0.740741  0.544218  0.627451       147\n",
            "      Negative   0.679426  0.662519  0.670866       643\n",
            "\n",
            "      accuracy                       0.660041      1962\n",
            "     macro avg   0.673861  0.526757  0.561296      1962\n",
            "  weighted avg   0.663815  0.660041  0.641640      1962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrvYzJMSSl2H",
        "outputId": "ef43f0d0-0fda-4361-86a6-c15de7383eeb"
      },
      "source": [
        "# ADABOOST #\n",
        "#seed = 10\n",
        "num_trees = 25\n",
        "\n",
        "ada_boost = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('ada_boost',\n",
        "                         AdaBoostClassifier(n_estimators=num_trees))\n",
        "                        ])\n",
        "ada_boost.fit(X_train, y_train)\n",
        "pred_ada_boost = ada_boost.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_ada_boost,y_test,ourTags,\"Ada Boost\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of Ada Boost: 0.4694189602446483\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.391304  0.067164  0.114650       134\n",
            " unknown_state   0.657143  0.089147  0.156997       258\n",
            "      Positive   0.452364  0.821795  0.583523       780\n",
            "Mixed_feelings   0.450704  0.217687  0.293578       147\n",
            "      Negative   0.519231  0.335925  0.407932       643\n",
            "\n",
            "      accuracy                       0.469419      1962\n",
            "     macro avg   0.494149  0.306344  0.311336      1962\n",
            "  weighted avg   0.496912  0.469419  0.416143      1962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVaP26seRJN8",
        "outputId": "4868e23a-47b7-40e9-e9e7-308b39e09be2"
      },
      "source": [
        "# XGBOOST #\n",
        "xg_boost = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('xgboost',\n",
        "                         XGBClassifier())\n",
        "                        ])\n",
        "xg_boost.fit(X_train, y_train)\n",
        "pred_xg_boost = xg_boost.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_xg_boost,y_test,ourTags,\"XGBoost\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of XGBoost: 0.5300713557594292\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.800000  0.029851  0.057554       134\n",
            " unknown_state   0.745098  0.147287  0.245955       258\n",
            "      Positive   0.479891  0.902564  0.626613       780\n",
            "Mixed_feelings   0.818182  0.122449  0.213018       147\n",
            "      Negative   0.661871  0.429238  0.520755       643\n",
            "\n",
            "      accuracy                       0.530071      1962\n",
            "     macro avg   0.701008  0.326278  0.332779      1962\n",
            "  weighted avg   0.621613  0.530071  0.472011      1962\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai2QQGdioGlJ",
        "outputId": "8cbb4e76-e4eb-4f68-d689-d58a304cb4eb"
      },
      "source": [
        "# XGBOOST #\n",
        "xg_boost = Pipeline([('vect', CountVectorizer(min_df=3, max_df=0.2, analyzer='word', ngram_range=(1, 3),)),\n",
        "                        ('tfidf', TfidfTransformer()),\n",
        "                        ('xgboost',\n",
        "                         XGBClassifier(learning_rate =0.1,\n",
        " n_estimators=1000,\n",
        " max_depth=5,\n",
        " min_child_weight=1,\n",
        " gamma=0,\n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " nthread=4,\n",
        " scale_pos_weight=1,\n",
        " seed=27))\n",
        "])\n",
        "xg_boost.fit(X_train, y_train)\n",
        "pred_xg_boost = xg_boost.predict(X_test)\n",
        "\n",
        "# prediction results\n",
        "utils.draw_prediction_results(pred_xg_boost,y_test,ourTags,\"XGBoost\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy of XGBoost: 0.6320081549439348\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "     not-Tamil   0.583333  0.261194  0.360825       134\n",
            " unknown_state   0.550633  0.337209  0.418269       258\n",
            "      Positive   0.653631  0.750000  0.698507       780\n",
            "Mixed_feelings   0.643411  0.564626  0.601449       147\n",
            "      Negative   0.625000  0.699844  0.660308       643\n",
            "\n",
            "      accuracy                       0.632008      1962\n",
            "     macro avg   0.611202  0.522575  0.547872      1962\n",
            "  weighted avg   0.625137  0.632008  0.618803      1962\n",
            "\n"
          ]
        }
      ]
    }
  ]
}